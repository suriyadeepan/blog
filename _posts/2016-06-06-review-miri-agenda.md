---
published: false
title: MIRI : Technical Agenda
layout: post
subtitle: Summary of Aligning Superintelligence with Human Interests 
tags: [ai]
---

Why worry?

They might cheat, take shortcuts.

What do we do?

* Theory before practice : Safety-critical
* 

## Highly Reliable Agent Design

### Realistic World-Models

### Decision Theory
What is a good decision? Is it good if the results it brings are good? Do ends justify means?

### Logical Uncertainty

### Vingean Reflection


## Error-Tolerant Agent Designs


## Value Specification
